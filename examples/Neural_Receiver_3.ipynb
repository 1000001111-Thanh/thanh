{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1e3c39cc",
      "metadata": {
        "id": "1e3c39cc"
      },
      "source": [
        "# Neural Receiver for OFDM SIMO Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69d31188",
      "metadata": {
        "id": "69d31188"
      },
      "source": [
        "## GPU Configuration and Imports <a class=\"anchor\" id=\"GPU-Configuration-and-Imports\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QYiZ55UuAl22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYiZ55UuAl22",
        "outputId": "1a181a0b-9a12-4358-e29e-11756a6f2e0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'thanh'...\n",
            "remote: Enumerating objects: 5591, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 5591 (delta 53), reused 48 (delta 48), pack-reused 5523 (from 3)\u001b[K\n",
            "Receiving objects: 100% (5591/5591), 153.22 MiB | 10.82 MiB/s, done.\n",
            "Resolving deltas: 100% (4091/4091), done.\n",
            "Updating files: 100% (3762/3762), done.\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/1000001111/thanh.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v4cyjy7jBFqj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4cyjy7jBFqj",
        "outputId": "9f5b81fa-4307-47de-9249-08d19d0080ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow<2.16.0,>=2.13.0 (from -r /content/thanh/requirements.txt (line 1))\n",
            "  Downloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r /content/thanh/requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/thanh/requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: matplotlib>=3.5.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/thanh/requirements.txt (line 4)) (3.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from -r /content/thanh/requirements.txt (line 5)) (6.5.2)\n",
            "Collecting mitsuba<3.6.0,>=3.2.0 (from -r /content/thanh/requirements.txt (line 6))\n",
            "  Downloading mitsuba-3.5.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting pythreejs>=2.4.2 (from -r /content/thanh/requirements.txt (line 7))\n",
            "  Downloading pythreejs-2.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from -r /content/thanh/requirements.txt (line 8))\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting ipydatawidgets==4.3.2 (from -r /content/thanh/requirements.txt (line 9))\n",
            "  Downloading ipydatawidgets-4.3.2-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting jupyterlab-widgets==3.0.5 (from -r /content/thanh/requirements.txt (line 10))\n",
            "  Downloading jupyterlab_widgets-3.0.5-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: traittypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipydatawidgets==4.3.2->-r /content/thanh/requirements.txt (line 9)) (0.2.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1))\n",
            "  Downloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1))\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (1.70.0)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1))\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1))\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1))\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->-r /content/thanh/requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->-r /content/thanh/requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->-r /content/thanh/requirements.txt (line 4)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->-r /content/thanh/requirements.txt (line 4)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->-r /content/thanh/requirements.txt (line 4)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->-r /content/thanh/requirements.txt (line 4)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->-r /content/thanh/requirements.txt (line 4)) (2.8.2)\n",
            "Collecting drjit==0.4.6 (from mitsuba<3.6.0,>=3.2.0->-r /content/thanh/requirements.txt (line 6))\n",
            "  Downloading drjit-0.4.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from pythreejs>=2.4.2->-r /content/thanh/requirements.txt (line 7)) (5.7.1)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->-r /content/thanh/requirements.txt (line 8))\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->-r /content/thanh/requirements.txt (line 8)) (7.34.0)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets>=8.0.4->-r /content/thanh/requirements.txt (line 8))\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "INFO: pip is looking at multiple versions of ipywidgets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting ipywidgets>=8.0.4 (from -r /content/thanh/requirements.txt (line 8))\n",
            "  Downloading ipywidgets-8.1.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.1.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->-r /content/thanh/requirements.txt (line 8)) (6.17.1)\n",
            "  Downloading ipywidgets-8.0.6-py3-none-any.whl.metadata (2.4 kB)\n",
            "INFO: pip is still looking at multiple versions of ipywidgets to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading ipywidgets-8.0.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (0.45.1)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->-r /content/thanh/requirements.txt (line 8))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->-r /content/thanh/requirements.txt (line 8)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->-r /content/thanh/requirements.txt (line 8)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->-r /content/thanh/requirements.txt (line 8)) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->-r /content/thanh/requirements.txt (line 8)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->-r /content/thanh/requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->-r /content/thanh/requirements.txt (line 8)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->-r /content/thanh/requirements.txt (line 8)) (4.9.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->-r /content/thanh/requirements.txt (line 8)) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->-r /content/thanh/requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->-r /content/thanh/requirements.txt (line 8)) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->-r /content/thanh/requirements.txt (line 1)) (3.2.2)\n",
            "Downloading ipydatawidgets-4.3.2-py2.py3-none-any.whl (271 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_widgets-3.0.5-py3-none-any.whl (384 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.3/384.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mitsuba-3.5.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (40.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading drjit-0.4.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pythreejs-2.4.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.0.5-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, widgetsnbextension, tensorflow-estimator, ml-dtypes, keras, jupyterlab-widgets, jedi, drjit, mitsuba, ipywidgets, tensorboard, ipydatawidgets, tensorflow, pythreejs\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: jupyterlab-widgets\n",
            "    Found existing installation: jupyterlab_widgets 3.0.13\n",
            "    Uninstalling jupyterlab_widgets-3.0.13:\n",
            "      Successfully uninstalled jupyterlab_widgets-3.0.13\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.1 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed drjit-0.4.6 ipydatawidgets-4.3.2 ipywidgets-8.0.5 jedi-0.19.2 jupyterlab-widgets-3.0.5 keras-2.15.0 mitsuba-3.5.2 ml-dtypes-0.3.2 pythreejs-2.4.2 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-estimator-2.15.0 widgetsnbextension-4.0.13 wrapt-1.14.1\n"
          ]
        }
      ],
      "source": [
        "# !pip install -r /content/thanh/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pTHjHPceBQNJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTHjHPceBQNJ",
        "outputId": "893155c8-e46e-440a-ed94-47d54b49279a"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6393b2fe",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-26T14:51:41.881148Z",
          "iopub.status.busy": "2024-09-26T14:51:41.880894Z",
          "iopub.status.idle": "2024-09-26T14:51:44.498124Z",
          "shell.execute_reply": "2024-09-26T14:51:44.497219Z"
        },
        "id": "6393b2fe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if os.getenv(\"CUDA_VISIBLE_DEVICES\") is None:\n",
        "    gpu_num = 0 # Use \"\" to use the CPU\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "\n",
        "import sys\n",
        "# sys.path.append('/content/thanh/')\n",
        "sys.path.append('../')\n",
        "import sionna\n",
        "# Import Sionna\n",
        "# try:\n",
        "#     import sionna\n",
        "# except ImportError as e:\n",
        "#     # Install Sionna if package is not already installed\n",
        "#     import os\n",
        "#     os.system(\"pip install sionna\")\n",
        "#     import sionna\n",
        "\n",
        "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
        "# For more details, see https://www.tensorflow.org/guide/gpu\n",
        "import tensorflow as tf\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "# Avoid warnings from TensorFlow\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "sionna.config.seed = 42 # Set seed for reproducible random number generation\n",
        "\n",
        "# Load the required Sionna components\n",
        "from sionna.nr import PUSCHConfig, PUSCHTransmitter, PUSCHReceiver, CarrierConfig, PUSCHDMRSConfig,\\\n",
        "                        TBConfig, PUSCHPilotPattern, TBEncoder, PUSCHPrecoder, LayerMapper, LayerDemapper, check_pusch_configs,\\\n",
        "                        TBDecoder, PUSCHLSChannelEstimator\n",
        "from sionna.nr.utils import generate_prng_seq\n",
        "from sionna.channel import AWGN, RayleighBlockFading, OFDMChannel, TimeChannel, time_lag_discrete_time_channel\n",
        "from sionna.channel.utils import *\n",
        "from sionna.channel.tr38901 import Antenna, AntennaArray, UMi, UMa, RMa, TDL, CDL\n",
        "from sionna.channel import gen_single_sector_topology as gen_topology\n",
        "from sionna.utils import compute_ber, ebnodb2no, sim_ber, array_to_hash, create_timestamped_folders, b2b, f2f, BinarySource\n",
        "from sionna.ofdm import KBestDetector, LinearDetector, MaximumLikelihoodDetector,\\\n",
        "        LSChannelEstimator, LMMSEEqualizer, RemoveNulledSubcarriers, ResourceGridDemapper,\\\n",
        "        ResourceGrid, ResourceGridMapper, OFDMModulator\n",
        "from sionna.mimo import StreamManagement\n",
        "from sionna.mapping import Mapper, Demapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6244a108",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-26T14:51:44.501712Z",
          "iopub.status.busy": "2024-09-26T14:51:44.501431Z",
          "iopub.status.idle": "2024-09-26T14:51:44.511679Z",
          "shell.execute_reply": "2024-09-26T14:51:44.511010Z"
        },
        "id": "6244a108"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "# from bs4 import BeautifulSoup\n",
        "import pickle\n",
        "from collections import namedtuple\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10b3af73",
      "metadata": {
        "id": "10b3af73"
      },
      "source": [
        "## Simulation Parameters <a class=\"anchor\" id=\"Simulation-Parameters\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2e2b69eb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-26T14:51:44.514347Z",
          "iopub.status.busy": "2024-09-26T14:51:44.514184Z",
          "iopub.status.idle": "2024-09-26T14:51:44.518257Z",
          "shell.execute_reply": "2024-09-26T14:51:44.517619Z"
        },
        "id": "2e2b69eb"
      },
      "outputs": [],
      "source": [
        "# _num_tx = 1\n",
        "# _num_rx = 1\n",
        "# _num_tx_ant = 1\n",
        "# _num_rx_ant = 8\n",
        "# _carrier_frequency = 2.55e9  # Carrier frequency in Hz.\n",
        "# _link_direction = \"uplink\"\n",
        "\n",
        "# # Configure antenna arrays\n",
        "# _ue_antenna = Antenna(polarization=\"single\",\n",
        "#                 polarization_type=\"V\",\n",
        "#                 antenna_pattern=\"38.901\",\n",
        "#                 carrier_frequency=_carrier_frequency)\n",
        "\n",
        "# _gnb_array = AntennaArray(num_rows=1,\n",
        "#                         num_cols=_num_rx_ant//2,\n",
        "#                         polarization=\"dual\",\n",
        "#                         polarization_type=\"cross\",\n",
        "#                         antenna_pattern=\"38.901\",\n",
        "#                         carrier_frequency=_carrier_frequency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "Y-Uxb7N9DnJ_",
      "metadata": {
        "id": "Y-Uxb7N9DnJ_"
      },
      "outputs": [],
      "source": [
        "class MyPUSCHConfig(PUSCHConfig):\n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            carrier_config=CarrierConfig(\n",
        "                n_cell_id=0,\n",
        "                cyclic_prefix=\"normal\",\n",
        "                subcarrier_spacing=30,\n",
        "                n_size_grid=273,\n",
        "                n_start_grid=0,\n",
        "                slot_number=4,\n",
        "                frame_number=0\n",
        "            ),\n",
        "            pusch_dmrs_config=PUSCHDMRSConfig(\n",
        "                config_type=1,\n",
        "                length=1,\n",
        "                additional_position=1,\n",
        "                dmrs_port_set=[0],\n",
        "                n_id=0,\n",
        "                n_scid=0,\n",
        "                num_cdm_groups_without_data=2,\n",
        "                type_a_position=2\n",
        "            ),\n",
        "            tb_config=TBConfig(\n",
        "                channel_type='PUSCH',\n",
        "                n_id=0,\n",
        "                mcs_table=1,\n",
        "                mcs_index=9\n",
        "            ),\n",
        "            mapping_type='A',\n",
        "            n_size_bwp=273,\n",
        "            n_start_bwp=0,\n",
        "            num_layers=1,\n",
        "            num_antenna_ports=1,\n",
        "            precoding='non-codebook',\n",
        "            tpmi=0,\n",
        "            transform_precoding=False,\n",
        "            n_rnti=2008,\n",
        "            symbol_allocation=[0,14]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "siO0XT0PDn0S",
      "metadata": {
        "id": "siO0XT0PDn0S"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Layer, Conv2D, LayerNormalization, SeparableConv2D\n",
        "from tensorflow.nn import relu\n",
        "class ResidualBlock(tf.keras.Model):\n",
        "    r\"\"\"\n",
        "    This Keras layer implements a convolutional residual block made of two convolutional layers with ReLU activation, layer normalization, and a skip connection.\n",
        "    The number of convolutional channels of the input must match the number of kernel of the convolutional layers ``num_conv_channel`` for the skip connection to work.\n",
        "\n",
        "    Input\n",
        "    ------\n",
        "    : [batch size, num time samples, num subcarriers, num_conv_channel], tf.float\n",
        "        Input of the layer\n",
        "\n",
        "    Output\n",
        "    -------\n",
        "    : [batch size, num time samples, num subcarriers, num_conv_channel], tf.float\n",
        "        Output of the layer\n",
        "    \"\"\"\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        # Layer normalization is done over the last three dimensions: time, frequency, conv 'channels'\n",
        "        self._layer_norm_1 = LayerNormalization(axis=(-1, -2, -3))\n",
        "        self._conv_1 = SeparableConv2D(filters= 64,\n",
        "                              kernel_size=[3,3],\n",
        "                              padding='same',\n",
        "                              activation=None)\n",
        "        # Layer normalization is done over the last three dimensions: time, frequency, conv 'channels'\n",
        "        self._layer_norm_2 = LayerNormalization(axis=(-1, -2, -3))\n",
        "        self._conv_2 = SeparableConv2D(filters= 128,\n",
        "                              kernel_size=[3,3],\n",
        "                              padding='same',\n",
        "                              activation=None)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z = self._layer_norm_1(inputs)\n",
        "        z = relu(z)\n",
        "        z = self._conv_1(z)\n",
        "        z = self._layer_norm_2(z)\n",
        "        z = relu(z)\n",
        "        z = self._conv_2(z) # [batch size, num time samples, num subcarriers, num_channels]\n",
        "        # Skip connection\n",
        "        z = z + inputs\n",
        "\n",
        "        return z\n",
        "\n",
        "class CustomNeuralReceiver(tf.keras.Model):\n",
        "    r\"\"\"\n",
        "    Keras layer implementing a residual convolutional neural receiver.\n",
        "\n",
        "    This neural receiver is fed with the post-DFT received samples, forming a resource grid of size num_of_symbols x fft_size, and computes LLRs on the transmitted coded bits.\n",
        "    These LLRs can then be fed to an outer decoder to reconstruct the information bits.\n",
        "\n",
        "    Input\n",
        "    ------\n",
        "    y_no: [batch size, num ofdm symbols, num subcarriers, 2*num rx antenna + 1], tf.float32\n",
        "        Concatenated received samples and noise variance.\n",
        "(\n",
        "    y : [batch size, num rx antenna, num ofdm symbols, num subcarriers], tf.complex\n",
        "        Received post-DFT samples.\n",
        "\n",
        "    no : [batch size], tf.float32\n",
        "        Noise variance. At training, a different noise variance value is sampled for each batch example.\n",
        ")\n",
        "    Output\n",
        "    -------\n",
        "    : [batch size, num ofdm symbols, num subcarriers, num_bits_per_symbol]\n",
        "        LLRs on the transmitted bits.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, training = False):\n",
        "        super(CustomNeuralReceiver, self).__init__()\n",
        "        self._training = training\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        # Input convolution\n",
        "        self._input_conv = Conv2D(filters= 128,\n",
        "                                  kernel_size=[3,3],\n",
        "                                  padding='same',\n",
        "                                  activation=None)\n",
        "        # Residual blocks\n",
        "        self._res_block_1 = ResidualBlock()\n",
        "        self._res_block_2 = ResidualBlock()\n",
        "        self._res_block_3 = ResidualBlock()\n",
        "        self._res_block_4 = ResidualBlock()\n",
        "        # Output conv\n",
        "        self._output_conv = Conv2D(filters= 2,    # QPSK\n",
        "                                   kernel_size=[3,3],\n",
        "                                   padding='same',\n",
        "                                   activation=None)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Input conv\n",
        "        z = self._input_conv(inputs)\n",
        "        # Residual blocks\n",
        "        z = self._res_block_1(z)\n",
        "        z = self._res_block_2(z)\n",
        "        z = self._res_block_3(z)\n",
        "        z = self._res_block_4(z)\n",
        "        # Output conv\n",
        "        z = self._output_conv(z)\n",
        "        # if self._training == False:\n",
        "        #     z = tf.cast(z * (2**7), tf.int8)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b8FPAeC1fJZL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8FPAeC1fJZL",
        "outputId": "debbd00c-d347-4901-d3ac-08441caa6ef5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"custom_neural_receiver\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             multiple                  18560     \n",
            "                                                                 \n",
            " residual_block (ResidualBl  multiple                  17630080  \n",
            " ock)                                                            \n",
            "                                                                 \n",
            " residual_block_1 (Residual  multiple                  17630080  \n",
            " Block)                                                          \n",
            "                                                                 \n",
            " residual_block_2 (Residual  multiple                  17630080  \n",
            " Block)                                                          \n",
            "                                                                 \n",
            " residual_block_3 (Residual  multiple                  17630080  \n",
            " Block)                                                          \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           multiple                  2306      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 70541186 (269.09 MB)\n",
            "Trainable params: 70541186 (269.09 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 1, 78624), dtype=float32, numpy=array([[[[0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_model = CustomNeuralReceiver(training = False)\n",
        "inputs = tf.zeros([1,3276,14,16])\n",
        "_model(inputs)\n",
        "_model.summary()\n",
        "\n",
        "def load_weights(model, pretrained_weights_path):\n",
        "    # Build Model with random input\n",
        "    # Load weights\n",
        "  with open(pretrained_weights_path, 'rb') as f:\n",
        "    weights = pickle.load(f)\n",
        "    model.set_weights(weights)\n",
        "    print(f\"Loaded pretrained weights from {pretrained_weights_path}\")\n",
        "\n",
        "# load_weights(_model, '/content/drive/MyDrive/Pusch_data/Model_weights/model_weight_FULL_RB_epoch_40.pkl')\n",
        "\n",
        "llr = _model(inputs)\n",
        "llr = tf.concat([llr[...,0:2,:],llr[...,3:11,:], llr[...,12:14,:]],axis=-2)\n",
        "llr = tf.transpose(llr, [0, 2, 1, 3])\n",
        "llr = tf.reshape(llr, [tf.shape(llr)[0], 1, 1, -1])\n",
        "llr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "IpfDB1ovFzW8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpfDB1ovFzW8",
        "outputId": "a52b046f-8c4e-460e-d4fe-5ced0a51ac3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XLA can lead to reduced numerical precision. Use with care.\n"
          ]
        }
      ],
      "source": [
        "# We need to enable sionna.config.xla_compat before we can use\n",
        "# tf.function with jit_compile=True.\n",
        "# See https://nvlabs.github.io/sionna/api/config.html#sionna.Config.xla_compat\n",
        "sionna.config.xla_compat=True\n",
        "\n",
        "class Model(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self._pusch_config = MyPUSCHConfig()\n",
        "        self._pusch_config.tb.mcs_index = 3\n",
        "\n",
        "\n",
        "        self._tb_size = self._pusch_config.tb_size\n",
        "        _num_coded_bits = self._pusch_config.num_coded_bits\n",
        "        self._target_coderate = self._pusch_config.tb.target_coderate\n",
        "        self._num_bits_per_symbol = self._pusch_config.tb.num_bits_per_symbol\n",
        "        _num_layers = self._pusch_config.num_layers\n",
        "        _n_rnti = self._pusch_config.n_rnti\n",
        "        _n_id = self._pusch_config.tb.n_id\n",
        "\n",
        "\n",
        "        self._binary_source = BinarySource(dtype=tf.float32)\n",
        "\n",
        "        self._tb_encoder = TBEncoder(\n",
        "                        target_tb_size=self._tb_size,\n",
        "                        num_coded_bits=_num_coded_bits,\n",
        "                        target_coderate=self._target_coderate,\n",
        "                        num_bits_per_symbol=self._num_bits_per_symbol,\n",
        "                        num_layers=_num_layers,\n",
        "                        n_rnti=_n_rnti,\n",
        "                        n_id=_n_id,\n",
        "                        channel_type=\"PUSCH\", # PUSCHTransmitter\n",
        "                        codeword_index=0, # not supported for PUSCH\n",
        "                        use_scrambler=True,\n",
        "                        verbose=False,\n",
        "                        output_dtype=tf.float32)\n",
        "\n",
        "        self._mapper = Mapper(\"qam\", self._num_bits_per_symbol, dtype=tf.complex64)\n",
        "\n",
        "        self._layer_mapper = LayerMapper(num_layers=_num_layers, dtype=tf.complex64)\n",
        "\n",
        "        _dmrs_length = self._pusch_config.dmrs.length\n",
        "        _dmrs_additional_position = self._pusch_config.dmrs.additional_position\n",
        "        _num_cdm_groups_without_data = self._pusch_config.dmrs.num_cdm_groups_without_data\n",
        "        _n_scid = self._pusch_config.dmrs.n_scid\n",
        "        _n_id_n_scid = self._pusch_config.dmrs.n_id[0]\n",
        "\n",
        "        _pilot_pattern = PUSCHPilotPattern([self._pusch_config],\n",
        "                                                dtype=tf.complex64)\n",
        "        _mu = 1\n",
        "        _num_ofdm_symbols = 14\n",
        "        _fft_size = 4096\n",
        "        _cyclic_prefix_length = 288\n",
        "        _subcarrier_spacing = 30e3\n",
        "        _num_guard_subcarriers = (410, 410)\n",
        "        _num_slots_per_frame = 20\n",
        "\n",
        "        # Define the resource grid.\n",
        "        self._resource_grid = ResourceGrid(\n",
        "            num_ofdm_symbols=_num_ofdm_symbols,\n",
        "            fft_size=_fft_size,\n",
        "            subcarrier_spacing=_subcarrier_spacing,\n",
        "            num_tx=1,\n",
        "            num_streams_per_tx=1,\n",
        "            cyclic_prefix_length=_cyclic_prefix_length,\n",
        "            num_guard_carriers=_num_guard_subcarriers,\n",
        "            dc_null=False,\n",
        "            pilot_pattern=_pilot_pattern,\n",
        "            dtype=tf.complex64\n",
        "        )\n",
        "\n",
        "        self._resource_grid_mapper = ResourceGridMapper(self._resource_grid, dtype=tf.complex64)\n",
        "\n",
        "        self._channel_estimator = PUSCHLSChannelEstimator(\n",
        "                        self._resource_grid,\n",
        "                        _dmrs_length,\n",
        "                        _dmrs_additional_position,\n",
        "                        _num_cdm_groups_without_data,\n",
        "                        interpolation_type='lin',\n",
        "                        dtype=tf.complex64)\n",
        "\n",
        "        self._model = _model\n",
        "\n",
        "        self._num_tx = 1\n",
        "        _num_rx = 1\n",
        "        _num_tx_ant = 1\n",
        "        _num_rx_ant = 8\n",
        "        _carrier_frequency = 2.55e9  # Carrier frequency in Hz.\n",
        "        _link_direction = \"uplink\"\n",
        "        _rx_tx_association = np.ones([_num_rx, self._num_tx], bool)\n",
        "        _stream_management = StreamManagement(_rx_tx_association, _num_layers)\n",
        "        self._mimo_detector = LinearDetector(\"lmmse\", \"bit\", \"maxlog\", self._resource_grid,\n",
        "                                        _stream_management, \"qam\",self. _num_bits_per_symbol, dtype=tf.complex64)\n",
        "        self._layer_demapper = LayerDemapper(self._layer_mapper, num_bits_per_symbol=self._num_bits_per_symbol)\n",
        "        self._tb_decoder = TBDecoder(self._tb_encoder, output_dtype=tf.float32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Configure antenna arrays\n",
        "        _ue_antenna = Antenna(polarization=\"single\",\n",
        "                        polarization_type=\"V\",\n",
        "                        antenna_pattern=\"38.901\",\n",
        "                        carrier_frequency=_carrier_frequency)\n",
        "\n",
        "        _gnb_array = AntennaArray(num_rows=1,\n",
        "                                num_cols=_num_rx_ant//2,\n",
        "                                polarization=\"dual\",\n",
        "                                polarization_type=\"cross\",\n",
        "                                antenna_pattern=\"38.901\",\n",
        "                                carrier_frequency=_carrier_frequency)\n",
        "\n",
        "        self._channel_model = CDL(model = 'A',\n",
        "                                  delay_spread = 150e-9,\n",
        "                                  carrier_frequency = _carrier_frequency,\n",
        "                                  ut_array = _ue_antenna,\n",
        "                                  bs_array = _gnb_array,\n",
        "                                  direction = _link_direction,\n",
        "                                  min_speed = 0)\n",
        "\n",
        "        # self._channel_model = UMi(carrier_frequency=_carrier_frequency,\n",
        "        #                           o2i_model=\"low\",\n",
        "        #                           ut_array=_ue_antenna,\n",
        "        #                           bs_array=_gnb_array,\n",
        "        #                           direction=\"uplink\",\n",
        "        #                           enable_pathloss=False,\n",
        "        #                           enable_shadow_fading=False)\n",
        "\n",
        "        self._channel = OFDMChannel(\n",
        "                            self._channel_model,\n",
        "                            self._resource_grid,\n",
        "                            normalize_channel=True,\n",
        "                            return_channel=True)\n",
        "\n",
        "\n",
        "\n",
        "    def new_topology(self, batch_size):\n",
        "        \"\"\"Set new topology\"\"\"\n",
        "        topology = gen_topology(batch_size,\n",
        "                                self._num_tx,\n",
        "                                'umi',\n",
        "                                min_ut_velocity=0,\n",
        "                                max_ut_velocity=0)\n",
        "\n",
        "        self._channel_model.set_topology(*topology)\n",
        "\n",
        "    @tf.function(jit_compile=True)\n",
        "    def call(self, batch_size, ebno_db):\n",
        "        # self.new_topology(batch_size)\n",
        "\n",
        "\n",
        "\n",
        "        b = self._binary_source([batch_size, self._num_tx, self._tb_size])\n",
        "        c = self._tb_encoder(b)\n",
        "        x_map = self._mapper(c)\n",
        "        x_layer = self._layer_mapper(x_map)\n",
        "        x = self._resource_grid_mapper(x_layer)\n",
        "\n",
        "\n",
        "        no = ebnodb2no(ebno_db,\n",
        "                       self._num_bits_per_symbol,\n",
        "                       self._target_coderate,\n",
        "                       self._resource_grid)\n",
        "        y, h = self._channel([x, no])\n",
        "\n",
        "\n",
        "        h_hat,err_var = self._channel_estimator([y, no])\n",
        "        # h_hat = h[...,410:-410]\n",
        "\n",
        "        llr_det = self._mimo_detector([y, h_hat, err_var, no])\n",
        "\n",
        "\n",
        "\n",
        "        llr = self._model(inputs)\n",
        "\n",
        "        llr = tf.concat([llr[...,0:2,:],llr[...,3:11,:], llr[...,12:14,:]],axis=-2)\n",
        "        llr = tf.transpose(llr, [0, 2, 1, 3])\n",
        "        llr_det = tf.reshape(llr, [tf.shape(llr)[0], 1, 1, -1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        llr_layer = self._layer_demapper(llr_det)\n",
        "\n",
        "        print(no, llr_layer)\n",
        "        bce = tf.nn.sigmoid_cross_entropy_with_logits(c, llr_layer)\n",
        "        bce = tf.reduce_mean(bce)\n",
        "        print(bce)\n",
        "\n",
        "\n",
        "        b_hat, tb_crc_status = self._tb_decoder(llr_layer)\n",
        "\n",
        "        return b, b_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HHQeIveQitRG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHQeIveQitRG",
        "outputId": "ca3a3ff1-3ba8-4701-b82b-8aa9f5aa5209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.50821376, shape=(), dtype=float32) tf.Tensor(\n",
            "[[[ 0.39727205 -0.06281994 -0.63921374 ...  0.00379648 -0.2373026\n",
            "   -0.23420796]]], shape=(1, 1, 78624), dtype=float32)\n",
            "tf.Tensor(0.75021863, shape=(), dtype=float32)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float64, numpy=0.49917796958487465>"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b, b_hat = Model()(1,7.0)\n",
        "compute_ber(b, b_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W_BLBAStLWuJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "W_BLBAStLWuJ",
        "outputId": "9574f3c9-803f-4a74-b467-3121a1b89586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n",
            "---------------------------------------------------------------------------------------------------------------------------------------\n",
            "     -5.0 | 2.9842e-01 | 1.0000e+00 |      743469 |     2491392 |          128 |         128 |       234.2 |reached target block errors\n",
            "     -4.5 | 2.3674e-01 | 1.0000e+00 |      589803 |     2491392 |          128 |         128 |        72.3 |reached target block errors\n",
            "     -4.0 | 1.5634e-01 | 1.0000e+00 |      389504 |     2491392 |          128 |         128 |        72.0 |reached target block errors\n",
            "     -3.5 | 1.1151e-01 | 1.0000e+00 |      277803 |     2491392 |          128 |         128 |        72.0 |reached target block errors\n",
            "     -3.0 | 8.0396e-02 | 9.7917e-01 |      225335 |     2802816 |          141 |         144 |        89.3 |reached target block errors\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-00e677f0e890>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                      0.5)\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_ber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mebno_dbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_target_block_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_mc_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/thanh/sionna/utils/misc.py\u001b[0m in \u001b[0;36msim_ber\u001b[0;34m(mc_fun, ebno_dbs, batch_size, max_mc_iter, soft_estimates, num_target_bit_errors, num_target_block_errors, target_ber, target_bler, early_stop, graph_mode, distribute, verbose, forward_keyboard_interrupt, callback, dtype)\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;31m# Raise Interrupt again to stop outer loops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforward_keyboard_interrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m         print(\"\\nSimulation stopped by the user \" \\\n",
            "\u001b[0;32m/content/thanh/sionna/utils/misc.py\u001b[0m in \u001b[0;36msim_ber\u001b[0;34m(mc_fun, ebno_dbs, batch_size, max_mc_iter, soft_estimates, num_target_bit_errors, num_target_block_errors, target_ber, target_bler, early_stop, graph_mode, distribute, verbose, forward_keyboard_interrupt, callback, dtype)\u001b[0m\n\u001b[1;32m    800\u001b[0m                                                 ebno_dbs[i])\n\u001b[1;32m    801\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmc_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mebno_db\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mebno_dbs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m                     \u001b[0;31m# assume first and second return value is b and b_hat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m                     \u001b[0;31m# other returns are ignored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    878\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "PUSCH_SIMS = {\n",
        "    \"bler\" : [],\n",
        "    \"ber\" : []\n",
        "    }\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "e2e = Model()\n",
        "ebno_dbs = np.arange(-5., # Min SNR for evaluation\n",
        "                     10., # Max SNR for evaluation\n",
        "                     0.5)\n",
        "\n",
        "ber, bler = sim_ber(e2e, ebno_dbs, batch_size=16, num_target_block_errors=128, max_mc_iter=100)\n",
        "print(ber, bler)\n",
        "\n",
        "PUSCH_SIMS[\"ber\"].append(list(ber.numpy()))\n",
        "PUSCH_SIMS[\"bler\"].append(list(bler.numpy()))\n",
        "\n",
        "PUSCH_SIMS[\"duration\"] = time.time() - start"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
